# input {
# 	beats {
# 		port => 5044
# 	}

# 	tcp {
# 		port => 50000
# 	}
# }

# ## Add your filters / logstash plugins configuration here

# output {
# 	elasticsearch {
# 		hosts => "elasticsearch:9200"
# 		user => "logstash_internal"
# 		password => "${LOGSTASH_INTERNAL_PASSWORD}"
# 	}
# }

# Custom logstash.conf for PCAP C2 Analysis Pipeline
input {
  file {
    path => "/usr/share/logstash/input_data/c2_analysis.json"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_c2"
    mode => "tail"
    codec => "json"
  }
}

filter {
  # The 'json' codec in the input block handles parsing.
  # Additional filters can be added here if needed, e.g., for data enrichment.
  
  mutate {
    # Convert string fields to appropriate numeric types if not handled by the template
    convert => {
      "packet_count" => "integer"
      "total_payload_size" => "integer"
      "connection_duration" => "float"
      "connection_interval" => "float"
      "average_jitter" => "float"
    }
  }
  
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "pcap-c2-analysis-%{+YYYY.MM.dd}"
    # user => "logstash_internal"
    # password => "${LOGSTASH_INTERNAL_PASSWORD}"
    # password => "GXD5YKdLzyhiidmbgsRb"
  }
  
  # Optional: Output to stdout for debugging purposes
  stdout {
    codec => rubydebug
  }
}